{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "negative    25000\n",
       "positive    25000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#leitura dos dados\n",
    "df_review = pd.read_csv(\"IMDB Dataset.csv\")\n",
    "#checagem do balanceamento\n",
    "df_review.value_counts(subset='sentiment')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset já veio perfeitamente balanceado. Nesse caso, não há necessidade de tomar qualquer ação nesse sentido.  \n",
    "De forma semelhante, os dados já estão limpos, não exigindo esse passo tampouco."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separação dos dados em treino e teste, utilizando proporção 80/20\n",
    "treino, teste = train_test_split(df_review, test_size=0.2, random_state=42)\n",
    "treino_x, treino_y = treino['review'], treino['sentiment']\n",
    "teste_x, teste_y = teste['review'], teste['sentiment']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "treino_x: variáveis independentes (review/análises) utilizadas para treinar o modelo. \n",
    "treino_y: variáveis dependentes/labels (sentiment) que o modelo deve prever.  \n",
    "teste_x: variáveis independentes que serão utilizadas para teste de precisão do modelo.  \n",
    "teste_y: labels/etiquetas usadas para testar a precisão da previsão do modelo contra as categorias de fato"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para transformar a representação textual em vetores numéricos, utilizaremos a técnica de bag of words (BOW).  \n",
    "A escolha se dá por: 1) a frequência das palavras nas análises importa, podendo ser indicador de seu sentimento; 2) a ordem em si das palavras possui menor relevância.  \n",
    "A BOW será representada por Term Frequency, Inverse Document Frequency (TF-IDF), forma de ponderar o peso de cada palavra de um documento (no caso, análise individual) levando em conta sua presença no corpus total (o conjunto de documentos/análises)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(stop_words='english') #remoção de stop words/palavras vazias da língua inglesa\n",
    "treino_x_vetor = tfidf.fit_transform(treino_x) #encontra parâmetros internos do modelo e os aplica, vetorizando o treino\n",
    "teste_x_vetor = tfidf.transform(teste_x) #apenas vetoriza o teste para uso\n",
    "treino_x_vetor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
