{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importação de todos os pacotes que serão utilizados ao longo do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "negative    25000\n",
       "positive    25000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#leitura dos dados\n",
    "df_review = pd.read_csv(\"IMDB Dataset.csv\")\n",
    "#checagem do balanceamento\n",
    "df_review.value_counts(subset='sentiment')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset já veio perfeitamente balanceado. Nesse caso, não há necessidade de tomar qualquer ação nesse sentido.  \n",
    "De forma semelhante, os dados já estão limpos, não exigindo esse passo tampouco."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separação dos dados em treino e teste, utilizando proporção 80/20\n",
    "treino, teste = train_test_split(df_review, test_size=0.2, random_state=42)\n",
    "treino_x, treino_y = treino['review'], treino['sentiment']\n",
    "teste_x, teste_y = teste['review'], teste['sentiment']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "treino_x: variáveis independentes (review/análises) utilizadas para treinar o modelo. \n",
    "treino_y: variáveis dependentes/labels (sentiment) que o modelo deve prever.  \n",
    "teste_x: variáveis independentes que serão utilizadas para teste de precisão do modelo.  \n",
    "teste_y: labels/etiquetas usadas para testar a precisão da previsão do modelo contra as categorias de fato"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para transformar a representação textual em vetores numéricos, utilizaremos a técnica de bag of words (BOW).  \n",
    "A escolha se dá por: 1) a frequência das palavras nas análises importa, podendo ser indicador de seu sentimento; 2) a ordem em si das palavras possui menor relevância.  \n",
    "A BOW será representada por Term Frequency, Inverse Document Frequency (TF-IDF), forma de ponderar o peso de cada palavra de um documento (no caso, análise individual) levando em conta sua presença no corpus total (o conjunto de documentos/análises)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(stop_words='english') #remoção de stop words/palavras vazias da língua inglesa\n",
    "treino_x_vetor = tfidf.fit_transform(treino_x) #encontra parâmetros internos do modelo e os aplica, vetorizando o treino\n",
    "teste_x_vetor = tfidf.transform(teste_x) #apenas vetoriza o teste para uso\n",
    "treino_x_vetor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teste de diferentes modelos de aprendizagem supervisionada (classificação) para selecionar aquele com maior precisão. Testaremos Support Vector Machines (SVM), árvore de decisões, Naive Bayes e regressão logística, comparando suas precisões médias (mean accuracy), F1 score, classification report e matriz de confusão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inserção dos dados nos algoritmos\n",
    "#SVM\n",
    "svc = SVC(kernel='linear')\n",
    "svc.fit(treino_x_vetor, treino_y)\n",
    "#Decision Tree\n",
    "dec_tree = DecisionTreeClassifier()\n",
    "dec_tree.fit(treino_x_vetor, treino_y)\n",
    "#Naive Bayes\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(treino_x_vetor.toarray(), treino_y)\n",
    "#Regressão logística\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(treino_x_vetor, treino_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mean Accuracy\n",
    "svc.score(teste_x_vetor, teste_y)\n",
    "dec_tree.score(teste_x_vetor, teste_y)\n",
    "gnb.score(teste_x_vetor.toarray(), teste_y)\n",
    "log_reg.score(teste_x_vetor, teste_y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como o resultado do Naive Bayes e das árvores de decisão foram consideravelmente abaixo daqueles apresentados pelo SVM e regressão logística, utilizaremos apenas esses dois últimos para os demais testes de comparação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#F1 score\n",
    "f1_score(teste_y, svc.predict(teste_x_vetor), \n",
    "         labels=['positive', 'negative'], average=None)\n",
    "f1_score(teste_y, log_reg.predict(teste_x_vetor), \n",
    "         labels=['positive', 'negative'], average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classification report\n",
    "print(classification_report(teste_y,\n",
    "                            svc.predict(teste_x_vetor),\n",
    "                            labels=['positive', 'negative']))\n",
    "print(classification_report(teste_y,\n",
    "                            log_reg.predict(teste_x_vetor),\n",
    "                            labels=['positive', 'negative']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion matrix\n",
    "conf_mat_svc = confusion_matrix(teste_y,\n",
    "                            svc.predict(teste_x_vetor),\n",
    "                            labels=['positive', 'negative'])\n",
    "conf_mat_logreg = confusion_matrix(teste_y,\n",
    "                            log_reg.predict(teste_x_vetor),\n",
    "                            labels=['positive', 'negative'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
